# Batch Mode Implementation Plan

## Overview

A Batch Mode modellekben **egyetlen modellt** tan√≠tunk az **√∂sszes strat√©gi√°ra** egyszerre, szemben a Per-Strategy m√≥ddal, ahol minden strat√©gi√°hoz k√ºl√∂n modell k√©sz√ºl. Ez 10-50x gyors√≠t√°st eredm√©nyez nagy sz√°m√∫ strat√©gia (6000+) eset√©n.

---

## M√°r Implement√°lt Batch Modellek

| Modell | F√°jl | St√°tusz |
|--------|------|---------|
| TimesNet | `src/analysis/models/dl_cnn/timesnet_batch.py` | ‚úÖ K√©sz |
| MTGNN | `src/analysis/models/dl_graph_specialized/mtgnn_batch.py` | ‚úÖ K√©sz |
| Autoformer | `src/analysis/models/dl_transformer/autoformer_batch.py` | ‚úÖ K√©sz |
| **Informer** | `src/analysis/models/dl_transformer/informer_batch.py` | ‚úÖ K√©sz |
| **PatchTST** | `src/analysis/models/dl_transformer/patchtst_batch.py` | ‚úÖ K√©sz |
| **TFT** | `src/analysis/models/dl_transformer/tft_batch.py` | ‚úÖ K√©sz |
| **Transformer** | `src/analysis/models/dl_transformer/transformer_batch.py` | ‚úÖ K√©sz |
| **iTransformer** | `src/analysis/models/dl_transformer/itransformer_batch.py` | ‚úÖ K√©sz |
| DeepAR | `src/analysis/models/dl_rnn/deepar_batch.py` | ‚úÖ K√©sz |
| ES-RNN | `src/analysis/models/dl_rnn/es_rnn_batch.py` | ‚úÖ K√©sz |
| GRU | `src/analysis/models/dl_rnn/gru_batch.py` | ‚úÖ K√©sz |
| LSTM | `src/analysis/models/dl_rnn/lstm_batch.py` | ‚úÖ K√©sz |
| MQRNN | `src/analysis/models/dl_rnn/mqrnn_batch.py` | ‚úÖ K√©sz |
| Seq2Seq | `src/analysis/models/dl_rnn/seq2seq_batch.py` | ‚úÖ K√©sz |
| DLinear | `src/analysis/models/dl_cnn/dlinear_batch.py` | ‚úÖ K√©sz |
| N-BEATS | `src/analysis/models/dl_cnn/nbeats_batch.py` | ‚úÖ K√©sz |
| N-HiTS | `src/analysis/models/dl_cnn/nhits_batch.py` | ‚úÖ K√©sz |
| TCN | `src/analysis/models/dl_cnn/tcn_batch.py` | ‚úÖ K√©sz |
| TiDE | `src/analysis/models/dl_cnn/tide_batch.py` | ‚úÖ K√©sz |
| FEDFormer | `src/analysis/models/dl_transformer/fedformer_batch.py` | ‚úÖ K√©sz |
| FiTS | `src/analysis/models/dl_transformer/fits_batch.py` | ‚úÖ K√©sz |
| **Diffusion** | `src/analysis/models/dl_graph_specialized/diffusion_batch.py` | ‚úÖ K√©sz |
| **KAN** | `src/analysis/models/dl_graph_specialized/kan_batch.py` | ‚úÖ K√©sz |
| **Neural ARIMA** | `src/analysis/models/dl_graph_specialized/neural_arima_batch.py` | ‚úÖ K√©sz |
| **Neural Basis Functions** | `src/analysis/models/dl_graph_specialized/rbf_batch.py` | ‚úÖ K√©sz |
| **Neural GAM** | `src/analysis/models/dl_graph_specialized/neural_gam_batch.py` | ‚úÖ K√©sz |
| **Neural ODE** | `src/analysis/models/dl_graph_specialized/neural_ode_batch.py` | ‚úÖ K√©sz |
| **Neural VAR** | `src/analysis/models/dl_graph_specialized/neural_var_batch.py` | ‚úÖ K√©sz |
| **Neural Volatility** | `src/analysis/models/dl_graph_specialized/neural_volatility_batch.py` | ‚úÖ K√©sz |
| **Spiking Neural Networks** | `src/analysis/models/dl_graph_specialized/snn_batch.py` | ‚úÖ K√©sz |
| **StemGNN** | `src/analysis/models/dl_graph_specialized/stemgnn_batch.py` | ‚úÖ K√©sz |

---

## Hi√°nyz√≥ Batch Implement√°ci√≥k

### CNN Modellek (`src/analysis/models/dl_cnn/`)

| Modell | Priorit√°s | Komplexit√°s | Megjegyz√©s |
|--------|-----------|-------------|------------|
| ~~**N-BEATS**~~ | ~~Magas~~ | ~~K√∂zepes~~ | ‚úÖ Implement√°lva |
| ~~**N-HiTS**~~ | ~~Magas~~ | ~~K√∂zepes~~ | ‚úÖ Implement√°lva |
| ~~**TCN**~~ | ~~K√∂zepes~~ | ~~K√∂zepes~~ | ‚úÖ Implement√°lva |
| ~~**DLinear**~~ | ~~Alacsony~~ | ~~Alacsony~~ | ‚úÖ Implement√°lva |
| ~~**TiDE**~~ | ~~K√∂zepes~~ | ~~K√∂zepes~~ | ‚úÖ Implement√°lva |

### Transformer Modellek (`src/analysis/models/dl_transformer/`)

| Modell | Priorit√°s | Komplexit√°s | Megjegyz√©s |
|--------|-----------|-------------|------------|
| ~~**Informer**~~ | ~~Magas~~ | ~~Magas~~ | ‚úÖ Implement√°lva |
| ~~**TFT**~~ | ~~Magas~~ | ~~Magas~~ | ‚úÖ Implement√°lva |
| ~~**PatchTST**~~ | ~~Magas~~ | ~~K√∂zepes~~ | ‚úÖ Implement√°lva |
| ~~**iTransformer**~~ | ~~K√∂zepes~~ | ~~K√∂zepes~~ | ‚úÖ Implement√°lva |
| ~~**FEDformer**~~ | ~~K√∂zepes~~ | ~~Magas~~ | ‚úÖ Implement√°lva |
| ~~**FITS**~~ | ~~Alacsony~~ | ~~Alacsony~~ | ‚úÖ Implement√°lva |
| ~~**Transformer**~~ | ~~K√∂zepes~~ | ~~K√∂zepes~~ | ‚úÖ Implement√°lva |

---

## Implement√°ci√≥s L√©p√©sek (Minden Modellhez)

### 1. F√ÅZIS: Batch F√°jl L√©trehoz√°sa

```
F√°jl elnevez√©s: {model_name}_batch.py
Helye: Ugyanaz a mappa mint az eredeti modell
```

**K√∂telez≈ë komponensek:**

#### 1.1 TradingRobustScaler oszt√°ly
```python
class TradingRobustScaler:
    """
    Trading adatokhoz optimaliz√°lt scaler.
    - Kezeli a ritka profit eloszl√°sokat (sok 0 √©rt√©k)
    - Non-zero √©rt√©kekb≈ël sz√°mol statisztik√°kat
    - Fallback mean/std-re ha IQR t√∫l kicsi
    """
    def __init__(self):
        self.center_ = None
        self.scale_ = None
        self._fitted = False

    def fit(self, x_input): ...
    def transform(self, x_input): ...
    def fit_transform(self, x_input): ...
    def inverse_transform(self, x_input): ...
```

#### 1.2 Batch Network oszt√°ly
```python
class {Model}BatchNetwork(nn.Module):
    """
    PyTorch network a batch tan√≠t√°shoz.
    - √ñsszes strat√©gia egyszerre batch-ben
    - K√∂z√∂s s√∫lyok minden strat√©gi√°ra
    """
    def __init__(self, input_size, hidden_size, output_size, ...):
        super().__init__()
        # R√©tegek defin√≠ci√≥ja

    def forward(self, x):
        # Forward pass
        return output
```

#### 1.3 Batch Model oszt√°ly
```python
class {Model}BatchModel:
    """
    F≈ë batch modell oszt√°ly.
    """
    def __init__(self, all_data, max_horizon, ...):
        self.all_data = all_data
        self.max_horizon = max_horizon
        self.scalers = {}  # KRITIKUS: Strategy-specifikus scalerek

    def _create_training_data(self):
        """
        √ñsszes strat√©gia adatainak √∂sszegy≈±jt√©se.
        FONTOS: Itt kell inicializ√°lni a scalereket!
        """
        for strat_id in self.all_data["No."].unique():
            scaler = TradingRobustScaler()
            scaled = scaler.fit_transform(strat_data)
            self.scalers[strat_id] = scaler  # Ment√©s k√©s≈ëbbi haszn√°latra

    def _prepare_sequences(self, look_back):
        """
        FONTOS: REUSE scalereket _create_training_data()-b√≥l!
        NE hozz l√©tre √∫j scalereket!
        """
        for strat_id in self.all_data["No."].unique():
            scaler = self.scalers[strat_id]  # M√°r l√©tez≈ë scaler
            scaled = scaler.transform(data)  # NEM fit_transform!

    def _train_model(self, device):
        """Modell tan√≠t√°s early stopping-gal."""

    def _predict_all_strategies(self, device):
        """
        Batch predikci√≥ + post-processing.
        FONTOS: Mean reversion alkalmaz√°sa!
        """

    def run(self, use_gpu=False, progress_callback=None, stop_callback=None):
        """F≈ë bel√©p√©si pont."""
```

### 2. F√ÅZIS: Engine.py Integr√°l√°s

**F√°jl:** `src/analysis/engine.py`

#### 2.1 Dispatch hozz√°ad√°sa (run() met√≥dusban, ~130-160 sor k√∂rny√©k√©n)
```python
if method_name == "{ModelName}":
    logger.info("Batch Mode enabled for {ModelName} -> Using {MODELNAME} BATCH")
    return self._run_{model_name}_batch(
        params, use_gpu, max_horizon, progress_callback, stop_callback
    )
```

#### 2.2 Legacy n√©v t√°mogat√°s (~200-230 sor)
```python
if method_name == "{ModelName} Batch":
    logger.info("Using {MODELNAME} BATCH MODE (Legacy Name)")
    return self._run_{model_name}_batch(
        params, use_gpu, max_horizon, progress_callback, stop_callback
    )
```

#### 2.3 √öj met√≥dus implement√°l√°sa (f√°jl v√©g√©hez)
```python
def _run_{model_name}_batch(
    self, params, use_gpu, max_horizon, progress_callback=None, stop_callback=None
):
    """Run {ModelName} in batch mode."""
    from analysis.models.{category}/{model_name}_batch import {Model}BatchModel

    if progress_callback:
        progress_callback(0, 1, "{ModelName} Batch: Initializing...")

    model = {Model}BatchModel(
        all_data=self.data,
        max_horizon=max_horizon,
        # Tov√°bbi param√©terek
    )

    results_df, all_strats_data = model.run(
        use_gpu=use_gpu,
        progress_callback=progress_callback,
        stop_callback=stop_callback,
    )

    # Best strategy kiv√°laszt√°sa
    if not results_df.empty:
        best_idx = results_df["Avg Profit"].idxmax()
        best_row = results_df.loc[best_idx]
        best_strat_id = int(best_row["No."])
        best_strat_data = all_strats_data.get(best_strat_id, {})
    else:
        best_strat_id = None
        best_strat_data = {}

    filename_base = f"{ModelName}_Batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    return results_df, best_strat_id, best_strat_data, filename_base, all_strats_data
```

### 3. F√ÅZIS: GPU Threshold Be√°ll√≠t√°s

**F√°jl:** `src/analysis/models/dl_utils/utils.py`

```python
GPU_SAMPLE_THRESHOLDS = {
    # ... existing entries ...
    "{ModelName} Batch": 50,  # Batch models always prefer GPU
}
```

### 4. F√ÅZIS: Tesztel√©s

#### 4.1 Test Script K√©sz√≠t√©se
```python
# test_{model_name}_batch.py
import pandas as pd
from analysis.models.{category}.{model_name}_batch import {Model}BatchModel

# Adatok bet√∂lt√©se
df = pd.read_parquet("testdata/AUDJPY_2020_2021_2022_2023_Weekly_Fix.parquet")

# Modell tesztel√©se
model = {Model}BatchModel(all_data=df, max_horizon=52)
results_df, all_strats = model.run(use_gpu=True)

print(f"Strategies: {len(results_df)}")
print(results_df.head(20))
```

#### 4.2 Ellen≈ërz√©si Pontok
- [ ] Modell hiba n√©lk√ºl fut
- [ ] Scalerek konzisztensek (train vs predict)
- [ ] Predikci√≥k re√°lis tartom√°nyban
- [ ] Mean reversion m≈±k√∂dik
- [ ] GPU/CPU v√°lt√°s m≈±k√∂dik
- [ ] Progress callback m≈±k√∂dik
- [ ] Stop callback m≈±k√∂dik
- [ ] Eredm√©nyek form√°tuma helyes

#### 4.3 Pylint Futtat√°s
```bash
pylint src/analysis/models/{category}/{model_name}_batch.py
```

---

## Auto Execution Integr√°ci√≥

Az Auto Execution automatikusan kezeli a Batch Mode-ot, ha a checkbox be van jel√∂lve.

**F√°jl:** `src/gui/auto_execution_mixin.py`

A `_start_analysis()` met√≥dus m√°r tartalmazza a sz√ºks√©ges logik√°t:
```python
use_batch = self.check_batch.isChecked() if hasattr(self, 'check_batch') else False
```

Nincs sz√ºks√©g tov√°bbi m√≥dos√≠t√°sra - az engine.py dispatch-eli a megfelel≈ë batch implement√°ci√≥t.

---

## Gomb M≈±k√∂d√©se (GUI)

**F√°jl:** `src/gui/tabs/analysis_tab.py`

### Batch Mode Toggle
```python
def toggle_batch_mode(self, state):
    """Toggle batch/global mode for models."""
    if state == Qt.Checked:
        # Deactivate mutually exclusive modes
        if hasattr(self, 'check_panel_mode'):
            self.check_panel_mode.setChecked(False)
        if hasattr(self, 'check_dual_model'):
            self.check_dual_model.setChecked(False)
```

### Mutual Exclusion
- Batch Mode ‚Üî Panel Mode ‚Üî Dual Model Mode
- Egyszerre csak egy lehet akt√≠v
- A toggle f√ºggv√©nyek automatikusan kezelik

---

## GPU Optimaliz√°ci√≥: CUDA Graphs

### Mi a CUDA Graphs?

A CUDA Graphs egy GPU optimaliz√°ci√≥s technika, amely **r√∂gz√≠ti (capture)** a GPU m≈±veleteket √©s **√∫jraj√°tssza (replay)** ≈ëket minim√°lis CPU overhead-del. Az inference loop-ban ez 10-30% gyorsul√°st eredm√©nyez.

### M≈±k√∂d√©si elv

```
Hagyom√°nyos inference:
  CPU ‚Üí GPU kernel launch ‚Üí GPU compute ‚Üí CPU ‚Üí GPU kernel launch ‚Üí ...
                 ‚Üë CPU overhead minden l√©p√©sn√©l

CUDA Graphs:
  Capture phase: CPU ‚Üí GPU kernel launch ‚Üí GPU compute ‚Üí ...
  Replay phase: GPU compute ‚Üí GPU compute ‚Üí GPU compute ‚Üí ...
                 ‚Üë Nincs CPU overhead a replay alatt!
```

### Implement√°ci√≥ Pattern

Minden Batch modell inference loop-j√°hoz hozz√° kell adni a k√∂vetkez≈ë k√≥dot:

```python
# Import a utils-b√≥l
from analysis.models.dl_utils.utils import create_cuda_graph_for_inference

# ... a run met√≥dusban, az inference el≈ëtt ...

with torch.inference_mode():
    # GPU OPTIMIZATION: Use CUDA Graphs for inference if on GPU
    cuda_graph = None
    use_cuda_graph = (
        device.type == "cuda"
        and steps >= 10
        and hasattr(torch.cuda, "CUDAGraph")
    )

    if use_cuda_graph:
        try:
            cuda_graph = create_cuda_graph_for_inference(
                model, current_batch, device, warmup=3
            )
            if not cuda_graph.is_enabled:
                cuda_graph = None
                logger.debug("Model: CUDA Graph not enabled, using standard inference")
        except Exception as cuda_err:
            logger.debug("Model: CUDA Graph creation failed: %s", cuda_err)
            cuda_graph = None

    for step in range(steps):
        # Check stop callback
        if stop_callback and stop_callback():
            if cuda_graph is not None:
                cuda_graph.cleanup()
            return {}

        try:
            # Use CUDA Graph if available
            if cuda_graph is not None:
                preds = cuda_graph.replay(current_batch)
            else:
                preds = model(current_batch)

            # ... process predictions ...

        except RuntimeError as e:
            if "CUDA" in str(e):
                if cuda_graph is not None:
                    cuda_graph.cleanup()
                    cuda_graph = None
                continue
            raise

    # Cleanup CUDA Graph
    if cuda_graph is not None:
        cuda_graph.cleanup()
```

### CUDA Graphs Implement√°ci√≥s St√°tusz

#### Batch Modellek
| Modell | CUDA Graphs | Megjegyz√©s |
|--------|-------------|------------|
| LSTM Batch | ‚úÖ K√©sz | Statikus input shape |
| GRU Batch | ‚úÖ K√©sz | Statikus input shape |
| ES-RNN Batch | ‚úÖ K√©sz | Statikus input shape |
| MQRNN Batch | ‚úÖ K√©sz | Statikus input shape |
| Autoformer Batch | ‚úÖ K√©sz | Statikus input shape |
| MTGNN Batch | ‚úÖ K√©sz | Statikus input shape |
| TimesNet Batch | ‚úÖ K√©sz | Statikus input shape |
| DeepAR Batch | ‚ö†Ô∏è Speci√°lis | Hidden state kezel√©s miatt bonyolultabb |

#### Per-Strategy (Nem-batch) Modellek - CUDA Graphs (2026-01-05)

**dl_graph_specialized (5+1 modell)**
| Modell | CUDA Graphs | Megjegyz√©s |
|--------|-------------|------------|
| neural_var.py | ‚úÖ K√©sz | Statikus input shape |
| neural_arima.py | ‚úÖ K√©sz | Statikus input shape |
| neural_quantile_regression.py | ‚úÖ K√©sz | Statikus input shape |
| neural_volatility.py | ‚úÖ K√©sz | Tuple output kezel√©s |
| rbf.py | ‚úÖ K√©sz | Statikus input shape |
| neural_gam.py | ‚è≠Ô∏è Kihagyva | K√©t input tensor - komplex |

**dl_cnn (6 modell)**
| Modell | CUDA Graphs | Megjegyz√©s |
|--------|-------------|------------|
| dlinear.py | ‚úÖ K√©sz | Statikus input shape |
| tcn.py | ‚úÖ K√©sz | Statikus input shape |
| tide.py | ‚úÖ K√©sz | Statikus input shape |
| nbeats.py | ‚úÖ K√©sz | 2D input_batch √°tv√°lt√°s |
| nhits.py | ‚úÖ K√©sz | 2D input_batch √°tv√°lt√°s |
| timesnet.py | ‚úÖ K√©sz | inference_mode() t√°mogat√°s |

**dl_rnn (4 modell)**
| Modell | CUDA Graphs | Megjegyz√©s |
|--------|-------------|------------|
| lstm.py | ‚úÖ K√©sz | Statikus input shape |
| gru.py | ‚úÖ K√©sz | Statikus input shape |
| es_rnn.py | ‚úÖ K√©sz | return_components kezel√©s |
| mqrnn.py | ‚úÖ K√©sz | Statikus input shape |
| seq2seq.py | ‚è≠Ô∏è Nem alkalmas | Egyszeri h√≠v√°s, nincs loop |
| deepar.py | ‚è≠Ô∏è Nem alkalmas | Hidden state √°tad√°s |

**dl_transformer (7 modell)**
| Modell | CUDA Graphs | Megjegyz√©s |
|--------|-------------|------------|
| autoformer.py | ‚úÖ K√©sz | Statikus input shape |
| informer.py | ‚úÖ K√©sz | Statikus input shape |
| fedformer.py | ‚úÖ K√©sz | Statikus input shape |
| patchtst.py | ‚úÖ K√©sz | Statikus input shape |
| itransformer.py | ‚úÖ K√©sz | Multivariate t√°mogat√°s |
| fits.py | ‚úÖ K√©sz | Statikus input shape |
| transformer.py | ‚úÖ K√©sz | Statikus input shape |

**√ñsszesen: 22 per-strategy modell kapott CUDA Graphs t√°mogat√°st.**

### Mikor NEM haszn√°lhat√≥ CUDA Graphs?

1. **Dinamikus input shape** - Ha az input m√©rete v√°ltozik fut√°s k√∂zben
2. **Control flow az inference-ben** - If/else a modellben
3. **Hidden state √°tad√°s** - DeepAR-n√°l a hidden state l√©p√©sr≈ël l√©p√©sre v√°ltozik
4. **CPU-GPU sync** - Ha gyakran kell szinkroniz√°lni

### V√°rhat√≥ gyorsul√°s

| Modell | Steps | Gyorsul√°s |
|--------|-------|-----------|
| Kis modell (LSTM/GRU) | 52 | 15-25% |
| K√∂zepes modell (ES-RNN) | 52 | 20-30% |
| Nagy modell (Autoformer) | 52 | 10-20% |
| MTGNN (sok strat√©gia) | 52 | 15-25% |

### Checklist √öj Batch Modellhez

- [ ] Import hozz√°ad√°sa: `from analysis.models.dl_utils.utils import create_cuda_graph_for_inference`
- [ ] CUDA Graph inicializ√°l√°s az inference loop el≈ëtt
- [ ] `cuda_graph.replay()` haszn√°lata ha el√©rhet≈ë
- [ ] Error handling √©s cleanup minden return el≈ëtt
- [ ] Cleanup az inference loop v√©g√©n

---

## Kritikus Hib√°k √©s Megold√°sok

### 1. Scaler Inkonzisztencia Bug
**Probl√©ma:** `_create_training_data()` √©s `_prepare_sequences()` k√ºl√∂nb√∂z≈ë scalereket haszn√°l.

**Megold√°s:**
```python
def _create_training_data(self):
    self.scalers = {}  # Inicializ√°l√°s
    for strat_id in ...:
        scaler = TradingRobustScaler()
        scaled = scaler.fit_transform(data)
        self.scalers[strat_id] = scaler  # Ment√©s

def _prepare_sequences(self, look_back):
    for strat_id in ...:
        scaler = self.scalers[strat_id]  # Reuse!
        scaled = scaler.transform(data)  # NEM fit_transform!
```

### 2. Batch Predikci√≥ Elt√©r√©s
**Probl√©ma:** Glob√°lis modell nem tanulja meg a strat√©gia-specifikus mint√°kat.

**Megold√°s:** Mean Reversion Post-Processing
```python
# Er≈ësebb mean reversion az els≈ë n√©h√°ny l√©p√©sben
if j == 0:
    val = val * 0.7 + recent_mean * 0.3
elif j < 4:
    blend = 0.25 + j * 0.05
    val = val * (1 - blend) + recent_mean * blend
```

### 3. Zero-Heavy Distributions
**Probl√©ma:** Trading adatok sok 0-t tartalmaznak (nincs trade).

**Megold√°s:** TradingRobustScaler
- Csak non-zero √©rt√©kekb≈ël sz√°mol statisztik√°kat
- Fallback mean/std-re ha nincs el√©g non-zero adat

---

## F√°jl Strukt√∫ra √ñsszefoglal√≥

```
src/
‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îú‚îÄ‚îÄ engine.py                    # Dispatch + _run_xxx_batch() met√≥dusok
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ dl_rnn/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ lstm.py             # Eredeti
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ lstm_batch.py       # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ gru.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ gru_batch.py        # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ seq2seq.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ seq2seq_batch.py    # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ mqrnn.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ mqrnn_batch.py      # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ deepar.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ deepar_batch.py     # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ es_rnn.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ es_rnn_batch.py     # ‚úÖ K√©sz
‚îÇ       ‚îú‚îÄ‚îÄ dl_cnn/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ timesnet.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ timesnet_batch.py   # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ nbeats.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ nbeats_batch.py     # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ nhits.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ nhits_batch.py      # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tcn.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tcn_batch.py        # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dlinear.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dlinear_batch.py    # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tide.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ tide_batch.py       # ‚úÖ K√©sz
‚îÇ       ‚îú‚îÄ‚îÄ dl_transformer/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ autoformer.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ autoformer_batch.py # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ informer.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ informer_batch.py   # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tft.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tft_batch.py        # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ patchtst.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ patchtst_batch.py   # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ itransformer.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ itransformer_batch.py # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fedformer.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fedformer_batch.py  # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fits.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fits_batch.py       # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ transformer.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ transformer_batch.py # ‚úÖ K√©sz
‚îÇ       ‚îú‚îÄ‚îÄ dl_graph_specialized/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ mtgnn.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ mtgnn_batch.py      # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ diffusion.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ diffusion_batch.py  # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ kan.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ kan_batch.py        # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neural_arima.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neural_arima_batch.py # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ rbf.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ rbf_batch.py        # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neural_gam.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neural_gam_batch.py # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neural_ode.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neural_ode_batch.py # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neural_volatility.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neural_volatility_batch.py # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ snn.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ snn_batch.py        # ‚úÖ K√©sz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ stemgnn.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ stemgnn_batch.py    # ‚úÖ K√©sz
‚îÇ       ‚îî‚îÄ‚îÄ dl_utils/
‚îÇ           ‚îî‚îÄ‚îÄ utils.py            # GPU thresholds
‚îî‚îÄ‚îÄ gui/
    ‚îú‚îÄ‚îÄ tabs/
    ‚îÇ   ‚îî‚îÄ‚îÄ analysis_tab.py         # Batch Mode toggle
    ‚îî‚îÄ‚îÄ auto_execution_mixin.py     # Auto Exec integr√°ci√≥
```

---

## Javasolt Implement√°ci√≥s Sorrend

1. ~~**LSTM Batch** - Legegyszer≈±bb, GRU mint√°j√°ra~~ ‚úÖ K√©sz
2. ~~**Seq2Seq Batch** - Encoder-Decoder alap√∫~~ ‚úÖ K√©sz
3. ~~**N-BEATS Batch** - N√©pszer≈±, block-alap√∫~~ ‚úÖ K√©sz
4. ~~**Informer Batch** - Fontos Transformer vari√°ns~~ ‚úÖ K√©sz
5. ~~**TFT Batch** - Gyakran haszn√°lt~~ ‚úÖ K√©sz
6. ~~**N-HiTS Batch** - N-BEATS hierarchikus verzi√≥ja~~ ‚úÖ K√©sz
7. ~~**PatchTST Batch** - Modern Transformer~~ ‚úÖ K√©sz
8. ~~**TCN Batch** - Dilated convolutions~~ ‚úÖ K√©sz
9. ~~**MQ-RNN Batch** - Multi-quantile~~ ‚úÖ K√©sz
10. ~~**iTransformer Batch** - Inverted attention~~ ‚úÖ K√©sz
11. ~~**FEDformer Batch** - Fourier alap√∫~~ ‚úÖ K√©sz
12. ~~**TiDE Batch** - Dense encoder~~ ‚úÖ K√©sz
13. ~~**DLinear Batch** - Egyszer≈± baseline~~ ‚úÖ K√©sz
14. ~~**FITS Batch** - Frequency interpolation~~ ‚úÖ K√©sz

---

## Checklist Minden Modellhez

- [ ] `{model}_batch.py` l√©trehozva a megfelel≈ë mapp√°ban
- [ ] TradingRobustScaler implement√°lva
- [ ] Batch Network oszt√°ly implement√°lva
- [ ] Batch Model oszt√°ly implement√°lva
- [ ] Scaler konzisztencia biztos√≠tva (fit vs transform)
- [ ] Mean reversion post-processing hozz√°adva
- [ ] `engine.py` dispatch hozz√°adva
- [ ] `engine.py` legacy n√©v t√°mogat√°s hozz√°adva
- [ ] `engine.py` `_run_xxx_batch()` met√≥dus implement√°lva
- [ ] `dl_utils/utils.py` GPU threshold hozz√°adva
- [ ] `parameters.py` MODEL_DEFAULTS √©s PARAM_OPTIONS bejegyz√©s hozz√°adva
- [ ] `parameter_spaces.py` Optuna space √©s regisztr√°ci√≥ hozz√°adva
- [ ] Test script futtatva
- [ ] Pylint hib√°k jav√≠tva
- [ ] GPU/CPU tesztelve
- [ ] Progress/Stop callback tesztelve

---

## J√∂v≈ëbeli GPU Optimaliz√°ci√≥k

### 1. CUDA Graphs Statikus Input Shape-hez

**St√°tusz:** ‚úÖ Implement√°lva 22+ modellben

A CUDA Graphs r√∂gz√≠ti a GPU m≈±veleteket √©s √∫jraj√°tssza ≈ëket minim√°lis CPU overhead-del.
L√°sd: "GPU Optimaliz√°ci√≥: CUDA Graphs" szekci√≥ fent.

### 2. Non-Blocking Data Transfer

**St√°tusz:** ‚úÖ Implement√°lva minden Batch modellben

```python
# M√°r implement√°lva a batch modellekben:
batch_x = batch_x.to(device, non_blocking=True)
batch_y = batch_y.to(device, non_blocking=True)

# DataLoader konfigur√°ci√≥:
pin_memory = device.type == "cuda"  # Enables pinned memory for faster transfers
```

### 3. GPU Sequential Mode Jav√≠t√°sa - P√°rhuzamos√≠t√°s

**St√°tusz:** üîÑ Tervez√©s alatt

**Probl√©ma:** Jelenleg a per-strategy mode szekvenci√°lisan dolgozza fel a strat√©gi√°kat.

**Megold√°si terv:**
```python
# 1. Mini-batch grouping a per-strategy modellekhez
def run_strategies_parallel(strategies, batch_size=8):
    """Process strategies in parallel batches on GPU."""
    for i in range(0, len(strategies), batch_size):
        batch = strategies[i:i+batch_size]
        # Process batch in parallel using torch.vmap or DataParallel
        results = process_batch(batch)
```

**Implement√°land√≥:**
- [ ] Strategy grouping by similar data length
- [ ] torch.vmap for vectorized per-strategy inference
- [ ] Memory-efficient parallel training with gradient accumulation

### 4. DataLoader num_workers Optimaliz√°ci√≥

**St√°tusz:** ‚úÖ R√©szben implement√°lva

**Jelenlegi be√°ll√≠t√°sok:**
```python
# GPU eset√©n:
num_workers = 2 if os.name == "nt" else 4  # Windows vs Linux

# CPU eset√©n:
num_workers = 0  # Nincs p√°rhuzamos adat bet√∂lt√©s
```

**Javasolt threshold cs√∂kkent√©s:**
- [x] Alacsonyabb threshold a Batch modellekhez (50 sample)
- [ ] Dinamikus num_workers dataset m√©ret alapj√°n:
  ```python
  # Proposed dynamic configuration
  if dataset_len > 10000:
      num_workers = 4 if os.name == "nt" else 8
  elif dataset_len > 1000:
      num_workers = 2 if os.name == "nt" else 4
  else:
      num_workers = 0  # Small datasets don't benefit from workers
  ```

### 5. P√°rhuzamos Strat√©gia Feldolgoz√°s

**St√°tusz:** üîÑ Tervez√©s alatt

**Megk√∂zel√≠t√©sek:**

#### 5.1 Multi-GPU T√°mogat√°s
```python
# torch.nn.DataParallel haszn√°lata t√∂bb GPU eset√©n
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)
```

#### 5.2 Strategy-Level Parallelism
```python
# T√∂bb strat√©gia p√°rhuzamos feldolgoz√°sa
from concurrent.futures import ThreadPoolExecutor

def process_strategies_parallel(strategies, model, max_workers=4):
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(process_strategy, s, model) for s in strategies]
        results = [f.result() for f in futures]
    return results
```

#### 5.3 CUDA Streams
```python
# P√°rhuzamos GPU m≈±veletek CUDA streams seg√≠ts√©g√©vel
streams = [torch.cuda.Stream() for _ in range(num_strategies)]
for i, (strategy, stream) in enumerate(zip(strategies, streams)):
    with torch.cuda.stream(stream):
        result = model(strategy)
torch.cuda.synchronize()  # Wait for all streams
```

---

## Param√©terez√©si Feladatok

### Batch Model Param√©ter Integr√°ci√≥ Checklist

Minden Batch modellhez sz√ºks√©ges param√©ter friss√≠t√©sek:

- [x] `parameters.py` ‚Üí `MODEL_DEFAULTS` - Alap√©rtelmezett param√©terek (batch-re optimaliz√°lva)
- [x] `parameters.py` ‚Üí `PARAM_OPTIONS` - GUI dropdown opci√≥k
- [x] `parameter_spaces.py` ‚Üí `get_{model}_batch_space()` - Optuna hyperparameter space
- [x] `parameter_spaces.py` ‚Üí `MODEL_SPACE_MAP` - Model regisztr√°ci√≥

### Batch-Specifikus Param√©ter Aj√°nl√°sok

| Param√©ter | Per-Strategy | Batch Mode | Indokl√°s |
|-----------|--------------|------------|----------|
| `batch_size` | 32-64 | 128-512 | T√∂bb adat = nagyobb batch |
| `epochs` | 25-50 | 10-20 | Konverg√°l gyorsabban |
| `learning_rate` | 0.001 | 0.001-0.005 | Nagyobb batch = nagyobb LR |
| `patience` | 3-5 | 4-8 | T√∂bb id≈ë a konverg√°l√°sra |
| `num_workers` | 0-2 | 2-4 | T√∂bb adat bet√∂lt√©se |

### Implement√°lt Batch Model Param√©terek

| Modell | MODEL_DEFAULTS | PARAM_OPTIONS | parameter_spaces.py |
|--------|----------------|---------------|---------------------|
| LSTM Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| GRU Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| DeepAR Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| ES-RNN Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| MQRNN Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| Seq2Seq Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| DLinear Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| N-BEATS Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| N-HiTS Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| TCN Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| TiDE Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| TimesNet Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| Autoformer Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| FEDFormer Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| FiTS Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| **Informer Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **PatchTST Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **TFT Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Transformer Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **iTransformer Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| MTGNN Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| Diffusion Batch | ‚úÖ | ‚úÖ | ‚úÖ |
| **KAN Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Neural ARIMA Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Neural Basis Functions Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Neural GAM Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Neural ODE Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Neural VAR Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Neural Volatility Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Spiking Neural Networks Batch** | ‚úÖ | ‚úÖ | ‚úÖ |
| **StemGNN Batch** | ‚úÖ | ‚úÖ | ‚úÖ |

---

*K√©sz√ºlt: 2026-01-03*
*Friss√≠tve: 2026-01-04 - Seq2Seq Batch, DLinear Batch, N-BEATS Batch, N-HiTS Batch, TCN Batch implement√°lva*
*Friss√≠tve: 2026-01-05 - CUDA Graphs implement√°lva 22 per-strategy modellben*
*Friss√≠tve: 2026-01-05 - TiDE Batch, FEDFormer Batch, FiTS Batch, Informer Batch, PatchTST Batch, **TFT Batch** implement√°lva*
*Friss√≠tve: 2026-01-05 - GPU optimaliz√°ci√≥s tervek, param√©terez√©si feladatok dokument√°lva*
*Friss√≠tve: 2026-01-06 - **Transformer Batch**, **iTransformer Batch** implement√°lva*
*Friss√≠tve: 2026-01-07 - **Diffusion Batch**, **KAN Batch**, **Neural ARIMA Batch** implement√°lva*
*Friss√≠tve: 2026-01-07 - **Neural ODE Batch** implement√°lva*
*Friss√≠tve: 2026-01-07 - **Neural Basis Functions Batch**, **Neural GAM Batch** implement√°lva*
*Friss√≠tve: 2026-01-07 - **Neural VAR Batch** implement√°lva*
*Friss√≠tve: 2026-01-07 - **Neural Volatility Batch** implement√°lva*
*Friss√≠tve: 2026-01-08 - **Spiking Neural Networks Batch** implement√°lva*
*Friss√≠tve: 2026-01-08 - **StemGNN Batch** implement√°lva*
*Verzi√≥: 4.2.17*
